{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA as a Factor Model - Coding Exercises\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "As we learned in the previous lessons, we can use PCA to create a factor model of risk. Our risk factor model represents the return as:\n",
    "\n",
    "$$\n",
    "\\textbf{r} = \\textbf{B}\\textbf{f} + \\textbf{s}\n",
    "$$\n",
    "\n",
    "where $\\textbf{r}$ is a matrix containing the asset returns, $\\textbf{B}$ is a matrix representing the factor exposures, $\\textbf{f}$ is the matrix of factor returns, and $\\textbf{s}$ is the idiosyncratic risk (also known as the company specific risk).\n",
    "\n",
    "In this notebook, we will use real stock data to calculate:\n",
    "\n",
    "* The Factor Exposures (Factor Betas) $\\textbf{B}$\n",
    "* The Factor Returns $\\textbf{f}$\n",
    "* The Idiosyncratic Risk Matrix $\\textbf{S}$\n",
    "* The Factor Covariance Matrix $\\textbf{F}$\n",
    "\n",
    "We will then combine these quantities to create our Risk Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipline===1.3.0 (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/59/8c5802a7897c1095fdc409fb557f04df8f75c37174e80d2ba58c8d8a6488/zipline-1.3.0.tar.gz (2.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.5MB 8.6MB/s eta 0:00:01    17% |█████▋                          | 430kB 14.1MB/s eta 0:00:01    67% |█████████████████████▊          | 1.7MB 29.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (18.1)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (38.4.0)\n",
      "Collecting Logbook>=0.12.5 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/d9/16ac346f7c0102835814cc9e5b684aaadea101560bb932a2403bd26b2320/Logbook-1.5.3.tar.gz (85kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 18.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2016.4 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2017.3)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.12.1)\n",
      "Collecting requests-file>=1.4.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Collecting pandas<=0.22,>=0.18.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/c6/0936bc5814b429fddb5d6252566fe73a3e40372e6ceaf87de3dec1326f28/pandas-0.22.0-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.3MB 797kB/s eta 0:00:01  0% |▏                               | 163kB 31.5MB/s eta 0:00:01    30% |█████████▉                      | 8.1MB 28.6MB/s eta 0:00:01    45% |██████████████▋                 | 12.0MB 30.1MB/s eta 0:00:01    65% |████████████████████▉           | 17.1MB 24.4MB/s eta 0:00:01    69% |██████████████████████▎         | 18.3MB 28.2MB/s eta 0:00:01    83% |██████████████████████████▊     | 21.9MB 26.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas-datareader>=0.2.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/52/accb990baebe0063977f26e02df36aa7eb4015ed4e86f828cd76273cd6f1/pandas_datareader-0.8.1-py2.py3-none-any.whl (107kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.18.4)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 19.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 16.4MB/s ta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 15.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (6.7)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (0.8.2)\n",
      "Collecting multipledispatch>=0.4.8 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.3.0->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1)) (1.1.13)\n",
      "Collecting alembic>=0.7.7 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 8.3MB/s eta 0:00:01    12% |████                            | 133kB 28.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/13/f3/cf85f7c3a2dbd1a515d51e1f1676d971abe41bba6f4ab5443240d9a78e5b/sortedcontainers-2.1.0-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/f9/76237755b2020cd74549e98667210b2dd54d3fb17c6f4a62631e61d31225/intervaltree-3.0.2.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/a5/32ed6e10246cd341ca8cc205acea5d208e4053f48a4dced2b1b31d45ba3f/lru-dict-1.1.6.tar.gz\n",
      "Collecting empyrical>=0.5.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/9e/9506e8b25464ff57ef93b5ba9092b464b44dc76b717695b126b3c93214a2/empyrical-0.5.3.tar.gz (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 11.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K    100% |████████████████████████████████| 4.3MB 7.3MB/s eta 0:00:01    69% |██████████████████████          | 3.0MB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trading-calendars>=1.0.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/1e/1ee0460a7c135bb1a2e37750603a64d81966eae74415eae426c793334ffa/trading_calendars-1.11.5.tar.gz (100kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 13.6MB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages (from pandas-datareader>=0.2.1->zipline===1.3.0->-r requirements.txt (line 1)) (4.1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Collecting python-editor>=0.3 (from alembic>=0.7.7->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Building wheels for collected packages: zipline, Logbook, cyordereddict, bottleneck, bcolz, alembic, intervaltree, lru-dict, empyrical, trading-calendars\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a4/d6/67/f303ab028b004bf8e00c05b5b04fba83d8ec238b6547becdb7\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/70/07/68b99a8e05dcd1ab194a8e0ccb9e4d0ac5dd6d8d139c7149b4\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for alembic ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/08/99/c0/5a5942f5b9567c59c14aac76f95a70bf11dccc71240b91ebf5\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/ef/06/fbdd555907a7d438fb33e4c8675f771ff1cf41917284c51ebf\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/10/a4/3b/951bd609878a82fd72b9ea23699daf1eaada4ff6f583152876\n",
      "  Running setup.py bdist_wheel for trading-calendars ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0c/c9/bd/0619ee358d9f8e374f80e378813e311e5c1ac960d0661242cc\n",
      "Successfully built zipline Logbook cyordereddict bottleneck bcolz alembic intervaltree lru-dict empyrical trading-calendars\n",
      "Installing collected packages: Logbook, requests-file, pandas, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, python-editor, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, trading-calendars, zipline\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "Successfully installed Logbook-1.5.3 alembic-1.4.1 bcolz-0.12.1 bottleneck-1.3.2 contextlib2-0.6.0.post1 cyordereddict-1.0.0 empyrical-0.5.3 intervaltree-3.0.2 lru-dict-1.1.6 multipledispatch-0.6.0 pandas-0.22.0 pandas-datareader-0.8.1 python-editor-1.0.4 requests-file-1.4.3 sortedcontainers-2.1.0 tables-3.6.1 trading-calendars-1.11.5 zipline-1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Returns\n",
    "\n",
    "In this notebook, we will get the stock returns using Zipline and data from Quotemedia, just as we learned in previous lessons. The function `get_returns(start_date, end_date)` in the `utils` module, gets the data from the Quotemedia data bundle and produces the stock returns for the given `start_date` and `end_date`. You are welcome to take a look at the `utils` module to see how this is done.\n",
    "\n",
    "In the code below, we use `utils.get_returns` funtion to get the returns for stock data between `2011-01-05` and `2016-01-05`. You can change the start and end dates, but if you do, you have to make sure the dates are valid trading dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Equity(0 [A])</th>\n",
       "      <th>Equity(1 [AAL])</th>\n",
       "      <th>Equity(2 [AAP])</th>\n",
       "      <th>Equity(3 [AAPL])</th>\n",
       "      <th>Equity(4 [ABBV])</th>\n",
       "      <th>Equity(5 [ABC])</th>\n",
       "      <th>Equity(6 [ABT])</th>\n",
       "      <th>Equity(7 [ACN])</th>\n",
       "      <th>Equity(8 [ADBE])</th>\n",
       "      <th>Equity(9 [ADI])</th>\n",
       "      <th>...</th>\n",
       "      <th>Equity(481 [XL])</th>\n",
       "      <th>Equity(482 [XLNX])</th>\n",
       "      <th>Equity(483 [XOM])</th>\n",
       "      <th>Equity(484 [XRAY])</th>\n",
       "      <th>Equity(485 [XRX])</th>\n",
       "      <th>Equity(486 [XYL])</th>\n",
       "      <th>Equity(487 [YUM])</th>\n",
       "      <th>Equity(488 [ZBH])</th>\n",
       "      <th>Equity(489 [ZION])</th>\n",
       "      <th>Equity(490 [ZTS])</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-07 00:00:00+00:00</th>\n",
       "      <td>0.008437</td>\n",
       "      <td>0.014230</td>\n",
       "      <td>0.026702</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>-0.007127</td>\n",
       "      <td>-0.005818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>-0.005619</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>-0.004044</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-10 00:00:00+00:00</th>\n",
       "      <td>-0.004174</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>-0.008896</td>\n",
       "      <td>-0.008854</td>\n",
       "      <td>0.028714</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>-0.006081</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.017945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11 00:00:00+00:00</th>\n",
       "      <td>-0.001886</td>\n",
       "      <td>-0.043644</td>\n",
       "      <td>-0.005927</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>0.007351</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>0.035676</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12 00:00:00+00:00</th>\n",
       "      <td>0.017254</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005979</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.022969</td>\n",
       "      <td>0.017950</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.014741</td>\n",
       "      <td>-0.011903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13 00:00:00+00:00</th>\n",
       "      <td>-0.004559</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>-0.000400</td>\n",
       "      <td>-0.005719</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030499</td>\n",
       "      <td>-0.003217</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-0.018235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005084</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.009178</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Equity(0 [A])  Equity(1 [AAL])  Equity(2 [AAP])  \\\n",
       "2011-01-07 00:00:00+00:00       0.008437         0.014230         0.026702   \n",
       "2011-01-10 00:00:00+00:00      -0.004174         0.006195         0.007435   \n",
       "2011-01-11 00:00:00+00:00      -0.001886        -0.043644        -0.005927   \n",
       "2011-01-12 00:00:00+00:00       0.017254        -0.008237         0.013387   \n",
       "2011-01-13 00:00:00+00:00      -0.004559         0.000955         0.003031   \n",
       "\n",
       "                           Equity(3 [AAPL])  Equity(4 [ABBV])  \\\n",
       "2011-01-07 00:00:00+00:00          0.007146               0.0   \n",
       "2011-01-10 00:00:00+00:00          0.018852               0.0   \n",
       "2011-01-11 00:00:00+00:00         -0.002367               0.0   \n",
       "2011-01-12 00:00:00+00:00          0.008133               0.0   \n",
       "2011-01-13 00:00:00+00:00          0.003657               0.0   \n",
       "\n",
       "                           Equity(5 [ABC])  Equity(6 [ABT])  Equity(7 [ACN])  \\\n",
       "2011-01-07 00:00:00+00:00         0.001994         0.004165         0.001648   \n",
       "2011-01-10 00:00:00+00:00        -0.005714        -0.008896        -0.008854   \n",
       "2011-01-11 00:00:00+00:00         0.009783        -0.002067         0.013717   \n",
       "2011-01-12 00:00:00+00:00        -0.005979        -0.001011         0.022969   \n",
       "2011-01-13 00:00:00+00:00         0.014925        -0.004451        -0.000400   \n",
       "\n",
       "                           Equity(8 [ADBE])  Equity(9 [ADI])  \\\n",
       "2011-01-07 00:00:00+00:00         -0.007127        -0.005818   \n",
       "2011-01-10 00:00:00+00:00          0.028714         0.002926   \n",
       "2011-01-11 00:00:00+00:00          0.000607         0.008753   \n",
       "2011-01-12 00:00:00+00:00          0.017950         0.000257   \n",
       "2011-01-13 00:00:00+00:00         -0.005719        -0.005012   \n",
       "\n",
       "                                 ...          Equity(481 [XL])  \\\n",
       "2011-01-07 00:00:00+00:00        ...                 -0.001838   \n",
       "2011-01-10 00:00:00+00:00        ...                  0.000947   \n",
       "2011-01-11 00:00:00+00:00        ...                  0.001314   \n",
       "2011-01-12 00:00:00+00:00        ...                  0.004986   \n",
       "2011-01-13 00:00:00+00:00        ...                  0.030499   \n",
       "\n",
       "                           Equity(482 [XLNX])  Equity(483 [XOM])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.005619           0.005461   \n",
       "2011-01-10 00:00:00+00:00            0.007814          -0.006081   \n",
       "2011-01-11 00:00:00+00:00            0.010179           0.007442   \n",
       "2011-01-12 00:00:00+00:00            0.015666           0.011763   \n",
       "2011-01-13 00:00:00+00:00           -0.003217           0.001694   \n",
       "\n",
       "                           Equity(484 [XRAY])  Equity(485 [XRX])  \\\n",
       "2011-01-07 00:00:00+00:00           -0.004044          -0.013953   \n",
       "2011-01-10 00:00:00+00:00            0.010466           0.009733   \n",
       "2011-01-11 00:00:00+00:00            0.007351           0.006116   \n",
       "2011-01-12 00:00:00+00:00            0.027182           0.004386   \n",
       "2011-01-13 00:00:00+00:00            0.000547          -0.018235   \n",
       "\n",
       "                           Equity(486 [XYL])  Equity(487 [YUM])  \\\n",
       "2011-01-07 00:00:00+00:00                0.0           0.012457   \n",
       "2011-01-10 00:00:00+00:00                0.0           0.001440   \n",
       "2011-01-11 00:00:00+00:00                0.0          -0.006470   \n",
       "2011-01-12 00:00:00+00:00                0.0           0.002631   \n",
       "2011-01-13 00:00:00+00:00                0.0          -0.005084   \n",
       "\n",
       "                           Equity(488 [ZBH])  Equity(489 [ZION])  \\\n",
       "2011-01-07 00:00:00+00:00          -0.000181           -0.010458   \n",
       "2011-01-10 00:00:00+00:00           0.007784           -0.017945   \n",
       "2011-01-11 00:00:00+00:00           0.035676            0.007467   \n",
       "2011-01-12 00:00:00+00:00           0.014741           -0.011903   \n",
       "2011-01-13 00:00:00+00:00          -0.004665           -0.009178   \n",
       "\n",
       "                           Equity(490 [ZTS])  \n",
       "2011-01-07 00:00:00+00:00                0.0  \n",
       "2011-01-10 00:00:00+00:00                0.0  \n",
       "2011-01-11 00:00:00+00:00                0.0  \n",
       "2011-01-12 00:00:00+00:00                0.0  \n",
       "2011-01-13 00:00:00+00:00                0.0  \n",
       "\n",
       "[5 rows x 490 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Get the returns for the fiven start and end date. Both dates must be valid trading dates\n",
    "returns = utils.get_returns(start_date='2011-01-05', end_date='2016-01-05')\n",
    "\n",
    "# Display the first rows of the returns\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Exposures\n",
    "\n",
    "In the code below, write a function, `factor_betas(pca, factor_beta_indices, factor_beta_columns)` that calculates the factor exposures from Scikit-Learn's `PCA()` class. Remember the matrix of factor exposures, $\\textbf{B}$, describes the coordintates of the Principal Components in the original basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `factor_beta_indices` parameter must be a 1 dimensional ndarray containg the column names of the `returns` dataframe. The `factor_beta_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor exposures, where the `factor_beta_indices` correspond to the indices of the dataframe and the `factor_beta_columns` correspond to the column names of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_betas(pca, factor_beta_indices, factor_beta_columns):\n",
    "\n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Retuns\n",
    "\n",
    "In the code below, write a function, `factor_returns(pca, returns, factor_return_indices, factor_return_columns)` that calculates the factor returns from Scikit-Learn's `PCA()` class. Remember the matrix of factor returns, $\\textbf{f}$, represents the `returns` written in the **new** basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_return_indices` parameter must be a 1 dimensional ndarray containing the trading dates (Pandas `DatetimeIndex`) in the `returns` dataframe. The `factor_return_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor returns, where the `factor_return_indices` correspond to the indices of the dataframe and the `factor_return_columns` correspond to the column names of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def factor_returns(pca, returns, factor_return_indices, factor_return_columns):\n",
    "    \n",
    "    #Implement Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Idiosyncratic Risk Matrix\n",
    "\n",
    "Let's review how we can calculate the Idiosyncratic Risk Matrix $\\textbf{S}$. We know that: \n",
    "\n",
    "$$\n",
    "\\textbf{s} = \\textbf{r} - \\textbf{B}\\textbf{f}\n",
    "$$\n",
    "\n",
    "We refer to $\\textbf{s}$ as the residuals. To calculate the idiosyncratic or specific risk matrix $\\textbf{S}$, we have to calculate the covariance matrix of the residuals, $\\textbf{s}$, and set the off-diagonal elements to zero. \n",
    "\n",
    "With this in mind, in the code below cerate a function, `idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor)` that calclates the **annualized** Idiosyncratic Risk Matrix. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_returns` parameter is the output of the `factor_returns()` function created above. Similarly, the `factor_betas` parameter is the output of the `factor_betas()` function created above. The `ann_factor` parameter is an integer representing the annualization factor. \n",
    "\n",
    "Remember that if the `returns` time series are daily returns, then when we calculate the Idiosyncratic Risk Matrix we will get values on a daily basis. We can annualize these values simply by multiplying the whole Idiosyncratic Risk Matrix by an annualization factor of 252. Remember we don't need the square root of the factor because our numbers here are variances not standard deviations.\n",
    "\n",
    "The function must return a pandas dataframe with the annualized Idiosyncratic Risk Matrix containing the covariance of the residuals in its main diagonal and with all the off-diagonal elements set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor):\n",
    "    \n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Covariance Matrix\n",
    "\n",
    "To calculate the annualized factor covariance matrix, $\\textbf{F}$, we use the following equation:\n",
    "\n",
    "$$\n",
    "\\textbf{F} = \\frac{1}{N -1}\\textbf{f}\\textbf{f}^T\n",
    "$$\n",
    "\n",
    "where, $N$ is the number of elements in $\\textbf{f}$. Recall that the factor covariance matrix, $\\textbf{F}$, is a diagonal matrix.\n",
    "\n",
    "With this in mind, create a function, `factor_cov_matrix(factor_returns, ann_factor)` that calculates the annualized factor covariance matrix from the factor returns $\\textbf{f}$. The `factor_returns` parameter is the output of the `factor_returns()` function created above and the `ann_factor` parameter is an integer representing the annualization factor. The function must return a diagonal numpy ndarray \n",
    "\n",
    "**HINT :** You can calculate the factor covariance matrix $\\textbf{F}$ very easily using Numpy's `.var` method. The $\\frac{1}{N -1}$ factor can be taken into account using the `ddof` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_cov_matrix(factor_returns, ann_factor):\n",
    " \n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Perfom PCA\n",
    "\n",
    "In the code below, create a function, `fit_pca(returns, num_factor_exposures, svd_solver)` that uses Scikit-Learn's `PCA()` class to fit the `returns` dataframe with the given number of `num_factor_exposures` (Principal Components) and with the given `svd_solver`. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `svd_solver` parameter is a string that determines the type of solver you want to use in your PCA algorithm. To see the type of solvers that you can use, see the [Scikit-Learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). The function must fit the `returns` and return the `pca` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fit_pca(returns, num_factor_exposures, svd_solver):\n",
    "\n",
    "    #TODO: Implement function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Create The Risk Model\n",
    "\n",
    "\n",
    "In the code below, create a class:\n",
    "\n",
    "```python\n",
    "class RiskModel(object):\n",
    "    def __init__(self, returns, ann_factor, num_factor_exposures, pca):\n",
    "```\n",
    "\n",
    "where the `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `ann_factor` parameter is an integer representing the annualization factor. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `pca` parameter is the output of the `fit_pca()` function created above. The class must contain all the fucntions created above. For example, to include the Factor covariance matrix we will use:\n",
    "\n",
    "```python\n",
    "self.factor_cov_matrix_ = factor_cov_matrix(self.factor_returns_, ann_factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RiskModel(object):\n",
    "    \n",
    "    #Implement class\n",
    "  \n",
    "\n",
    "# Set the annualized factor\n",
    "ann_factor = \n",
    "\n",
    "# Set the number of factor exposures (principal components) for the PCA algorithm\n",
    "num_factor_exposures = \n",
    "\n",
    "# Set the svd solver for the PCA algorithm\n",
    "svd_solver = 'full'\n",
    "\n",
    "# Fit the PCA Model using the fit_pca() fucntion \n",
    "pca = \n",
    "\n",
    "# Create a RiskModel object\n",
    "rm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Exposures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Idiosyncratic Risk Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Idiosyncratic Risk Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Covariance Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View The Percent of Variance Explained by Each Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "# Make the bar plot\n",
    "plt.bar(np.arange(num_factor_exposures), pca.explained_variance_ratio_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first factor dominates. The precise defintion of each factor in a latent model is unknown, however we can guess at the likely intepretation.\n",
    "\n",
    "# View The Factor Returns\n",
    "\n",
    "Remember that the factors returns don't necessarily have direct interpretations in the real world but you can thinik of them as returns time series for some kind of latent or unknown driver of return variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "rm.factor_returns_.loc[:,0:5].cumsum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "[Solution notebook](pca_factor_model_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
